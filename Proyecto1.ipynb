{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crear un entorno de anaconda con los paquetes que considere necesarios.\n",
    "2. Usando sclicing con NumPy separar los datos en 2 datasets: entrenamiento(80 %) y validaci ́on y pruebas(20 %).\n",
    "3. Analisis exploratorio de datos: Para cada variable en el dataset calcular(usando numpy o pandas): media, valor maximo, valor mınimo, rango, desviacion estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar dataset a una variable\n",
    "dataset = np.load(\"proyecto_training_data.npy\")\n",
    "\n",
    "# Separar dataset en 2 nuevos datasets 80% y 20%\n",
    "split_idx = int(len(dataset) * 0.8)\n",
    "train_data = dataset[:split_idx]\n",
    "test_data = dataset[split_idx:]\n",
    "\n",
    "# Calcular media, max, min, rango y desviacion estandar\n",
    "value_means = np.mean(train_data, axis=0)\n",
    "value_max = np.max(train_data, axis=0)\n",
    "value_min = np.min(train_data, axis=0)\n",
    "value_range = np.ptp(train_data, axis=0)\n",
    "value_deviation = np.std(train_data, axis=0)\n",
    "#print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Para cada variable en el dataset usar seaborn para graficar un histograma de la variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar dataset a una variable\n",
    "dataset = np.load(\"proyecto_training_data.npy\")\n",
    "\n",
    "# Convertir el ndarray a un DataFrame\n",
    "dataframe = pd.DataFrame(dataset)\n",
    "\n",
    "# Mostrar el histograma de la columna 0\n",
    "sns.histplot(data=dataframe, x=0, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar dataset a una variable\n",
    "dataset = np.load(\"proyecto_training_data.npy\")\n",
    "\n",
    "# Convertir el ndarray a un DataFrame\n",
    "dataframe = pd.DataFrame(dataset)\n",
    "\n",
    "# Crear un ciclo para generar histogramas por cada columna\n",
    "for i in range(6):\n",
    "    # Obtener el nombre de la columna en la iteración actual\n",
    "    columna = dataframe.columns[i]\n",
    "    \n",
    "    # Crear el histograma utilizando Seaborn\n",
    "    sns.histplot(data=dataframe, x=columna, kde=True)\n",
    "    \n",
    "    # Agregar etiquetas y título\n",
    "    plt.xlabel(columna)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title('Histograma de la columna: {}'.format(columna))\n",
    "    \n",
    "    # Mostrar el histograma\n",
    "    plt.show()\n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Para cada variable independiente x :\n",
    "- Calcular el coeficiente de correlaci ́on entre x y y.\n",
    "- Graficar x vs y(scatterplot) usando matplotlib.\n",
    "- Colocar el coeficiente de correlaci ́on y colocarlo como parte del t ́ıtulo de la gr ́afica.\n",
    "- Basado en la gr afica y el coeficiente de correlaci ́on de cada par x,y elegir las 2 variables con mas potencial predictivo es decir las 2 variables que presentan mayor correlacion entre dicha variable y la variable dependiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El coeficiente de correlacion del primer arreglo es 0.7909816005838053\n",
      "El coeficiente de correlacion del segundo arreglo es 0.40951597886683166\n",
      "El coeficiente de correlacion del tercer arreglo es 0.12334946703331619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar dataset a una variable\n",
    "dataset = np.load(\"proyecto_training_data.npy\")\n",
    "\n",
    "# Convertir el ndarray a un DataFrame\n",
    "dataframe_original = pd.DataFrame(dataset)\n",
    "\n",
    "# Separar el dataframe original en 3 nuevos dataframes con X y Y\n",
    "dataframe1 = dataframe_original[[1, 0]]\n",
    "dataframe2 = dataframe_original[[3, 2]]\n",
    "dataframe3 = dataframe_original[[5, 4]]\n",
    "\n",
    "# Calculando los coeficientes de correlacion\n",
    "coefficient1 = dataframe1.corr().iloc[0, 1]\n",
    "coefficient2 = dataframe2.corr().iloc[0, 1]\n",
    "coefficient3 = dataframe3.corr().iloc[0, 1]\n",
    "\n",
    "# Mostrar los coeficientes de correlacion\n",
    "print(\"El coeficiente de correlacion del primer arreglo es\", coefficient1)\n",
    "print(\"El coeficiente de correlacion del segundo arreglo es\", coefficient2)\n",
    "print(\"El coeficiente de correlacion del tercer arreglo es\", coefficient3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
